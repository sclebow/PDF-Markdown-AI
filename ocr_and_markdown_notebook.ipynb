{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf408011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a python script that takes a large PDF file and splits it into smaller chunks.\n",
    "# Then it converts each chunk into markdown format, by sending the text to OpenAI's GPT model.\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import openai\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image\n",
    "import base64\n",
    "import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.cloud import vision\n",
    "\n",
    "POPPLER_PATH = r\"C:\\Program Files\\poppler-24.08.0\\Library\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93f40047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_google_vision(image_path):\n",
    "    \"\"\"\n",
    "    Use Google Cloud Vision OCR to extract text from the image.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    \n",
    "    output = \"\"\n",
    "    vertices_list = []\n",
    "\n",
    "    # print(\"Texts:\")\n",
    "    for text in texts:\n",
    "        # print(f'\\n\"{text.description}\"')\n",
    "        vertices = text.bounding_poly.vertices\n",
    "        # print(\"Vertices:\")\n",
    "        for vertex in vertices:\n",
    "            # print(f\"({vertex.x}, {vertex.y})\")\n",
    "            # Convert to a list of tuples\n",
    "            vertices_list.append((vertex.x, vertex.y))\n",
    "        vertices_list.append(vertices)\n",
    "        \n",
    "        output += text.description + \"\\n\"\n",
    "\n",
    "    # print(f\"Full text: {output}\")\n",
    "\n",
    "    return output, vertices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6b1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ocr_text_and_image_to_markdown(ocr_text, image_file_path, client, log_dir=None):\n",
    "    \"\"\"\n",
    "    Sends both the OCR text and the original image to ChatGPT, instructing it to only arrange the OCR text into markdown,\n",
    "    not to transcribe from the image.\n",
    "    \"\"\"\n",
    "    with open(image_file_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    column_headers = [\n",
    "        \"ID\",\n",
    "        \"Name\",\n",
    "        \"Crew\",\n",
    "        \"Daily Output\",\n",
    "        \"Labor-Hours\",\n",
    "        \"Unit\",\n",
    "        \"Material\",\n",
    "        \"Labor\",\n",
    "        \"Equipment\",\n",
    "        \"Total\",\n",
    "        \"Total Incl O&P\",\n",
    "    ]\n",
    "\n",
    "    prompt = (\n",
    "        \"You are given the OCR-extracted text from an image and the original image itself. \"\n",
    "        \"Your task is to arrange the provided OCR text into markdown format, preserving any tables or structure. \"\n",
    "        \"Do NOT transcribe or extract any new information from the image. \"\n",
    "        \"Only use the provided OCR text. \"\n",
    "        \"If the OCR text is unclear, leave it as is. \"\n",
    "        \"Do not add, guess, or hallucinate any information. \"\n",
    "        \"If a table contains blank or empty cells, preserve them as blank in the markdown table (do not fill or merge them). \"\n",
    "        \"Keep the table structure and number of columns/rows as in the original text, even if some cells are empty. \"\n",
    "        f\"The table columns are: {', '.join(column_headers)}. \"\n",
    "        \"Provide only the markdown output, without any extra commentary or code blocks.\\n\\n\"\n",
    "        \"OCR Text:\\n\"\n",
    "        f\"{ocr_text}\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    markdown_text = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Logging\n",
    "    if log_dir is not None:\n",
    "        log_file_path = os.path.join(log_dir, \"conversion_log.txt\")\n",
    "        with open(log_file_path, 'a', encoding='utf-8') as log_file:\n",
    "            log_file.write(f\"Timestamp: {datetime.datetime.now().isoformat()}\\n\")\n",
    "            log_file.write(f\"Image: {image_file_path}\\n\")\n",
    "            log_file.write(\"OCR Text:\\n\")\n",
    "            log_file.write(ocr_text + \"\\n\")\n",
    "            log_file.write(\"Prompt:\\n\")\n",
    "            log_file.write(prompt + \"\\n\")\n",
    "            log_file.write(\"GPT Markdown Output:\\n\")\n",
    "            log_file.write(markdown_text + \"\\n\")\n",
    "            log_file.write(\"=\"*60 + \"\\n\\n\")\n",
    "\n",
    "    return markdown_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1bf6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_markdown(markdown_text, output_path):\n",
    "    \"\"\"\n",
    "    Saves the markdown text to a file.\n",
    "    \n",
    "    Args:\n",
    "        markdown_text (str): The markdown text to be saved.\n",
    "        output_path (str): The path where the markdown file will be saved.\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4e71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23900377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_for_directory(root, title=\"Select Directory\"):\n",
    "    # Use a file dialog to get the directory to save markdown files\n",
    "    markdown_directory = filedialog.askdirectory(\n",
    "        title=title,\n",
    "    )\n",
    "    \n",
    "    # If user cancels the dialog\n",
    "    if not markdown_directory:\n",
    "        print(\"No directory selected. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    return markdown_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ec6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_patches(image_file_path):\n",
    "    \"\"\"\n",
    "    Calculate the number of patches in the image file.\n",
    "    \n",
    "    Args:\n",
    "        image_file_path (str): The path to the image file.\n",
    "    \n",
    "    Returns:\n",
    "        int: The number of patches in the image.\n",
    "    \"\"\"\n",
    "    # The number of patches is calculated based on the image size\n",
    "    # Each patch is 32x32 pixels\n",
    "    image = Image.open(image_file_path)\n",
    "    width, height = image.size\n",
    "    num_x_patches = (width + 32 - 1) // 32 # Ceiling division\n",
    "    num_y_patches = (height + 32 - 1) // 32 # Ceiling division\n",
    "    num_patches = num_x_patches * num_y_patches\n",
    "\n",
    "    return num_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d86909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a root window\n",
    "root = tk.Tk()\n",
    "\n",
    "# Read the OpenAI API key from the text file\n",
    "openai_key_file_path = os.path.join(os.getcwd(), \"openai_key.txt\")\n",
    "if os.path.exists(openai_key_file_path):\n",
    "    with open(openai_key_file_path, 'r') as key_file:\n",
    "        openai_api_key = key_file.read().strip()\n",
    "else:\n",
    "    print(\"API key file not found. Please provide the API key manually.\")\n",
    "    openai_api_key = \"\"\n",
    "\n",
    "# Prompt the user to provide OpenAI API key using Tkinter\n",
    "openai_api_key = tk.simpledialog.askstring(\n",
    "    \"OpenAI API Key\",\n",
    "    \"Enter your OpenAI API key:\",\n",
    "    initialvalue=openai_api_key\n",
    ")\n",
    "if not openai_api_key:\n",
    "    print(\"No API key provided. Exiting.\")\n",
    "    root.destroy()\n",
    "    exit(1)\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Destroy the root window\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e25106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a root window\n",
    "root = tk.Tk()\n",
    "\n",
    "# Using TKinter, prompt the user to provide Google Cloud API json key\n",
    "google_cloud_key_file_path = os.path.join(os.getcwd(), \"google_cloud_key.json\")\n",
    "if os.path.exists(google_cloud_key_file_path):\n",
    "    with open(google_cloud_key_file_path, 'r') as key_file:\n",
    "        google_cloud_api_key = key_file.read().strip()\n",
    "else:\n",
    "    print(\"Google Cloud API key file not found. Please provide the API key manually.\")\n",
    "    google_cloud_api_key = \"\"\n",
    "\n",
    "# Prompt the user to provide Google Cloud API key using Tkinter file dialog\n",
    "google_cloud_key_file_path = filedialog.askopenfilename(\n",
    "    title=\"Select Google Cloud API Key File\",\n",
    "    filetypes=[(\"JSON files\", \"*.json\")],\n",
    "    initialdir=os.getcwd()\n",
    ")\n",
    "\n",
    "# Set the environment variable for Google Cloud API key\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = google_cloud_key_file_path\n",
    "\n",
    "# Destroy the root window\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701d437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a root window\n",
    "root = tk.Tk()\n",
    "\n",
    "# Prompt the user for the file path of the image files\n",
    "image_directory = prompt_user_for_directory(root, \"Select Directory with Image Files\")\n",
    "if not image_directory:\n",
    "    print(\"No directory selected. Exiting.\")\n",
    "    root.destroy()\n",
    "    exit()\n",
    "\n",
    "markdown_directory = image_directory  # Save markdown files in the same directory as images\n",
    "\n",
    "# Destroy the root window\n",
    "root.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac18992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted image files:\n",
      "page_139.jpg\n"
     ]
    }
   ],
   "source": [
    "# Get the list of image files in the directory\n",
    "image_files = [f for f in os.listdir(image_directory) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "if not image_files:\n",
    "    print(\"No image files found in the selected directory.\")\n",
    "\n",
    "# Sort the image files by the number in the filename\n",
    "image_numbers = {}\n",
    "for image_file in image_files:\n",
    "    # Extract the number from the filename\n",
    "    number = ''.join(filter(str.isdigit, image_file))\n",
    "    if number:\n",
    "        image_numbers[image_file] = int(number)\n",
    "image_files.sort(key=lambda x: image_numbers.get(x, float('inf')))\n",
    "# Print the sorted image files\n",
    "print(\"Sorted image files:\")\n",
    "for image_file in image_files:\n",
    "    print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f42aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ocr_text_and_vertices_to_markdown(ocr_text, vertices_list, client, log_dir):\n",
    "    \"\"\"\n",
    "    Sends both the OCR text and the vertices list to ChatGPT, instructing it to only arrange the OCR text into markdown,\n",
    "    not to transcribe from the image.\n",
    "    \"\"\"\n",
    "    # Convert vertices list to string\n",
    "    vertices_str = \"\\n\".join([str(vertices) for vertices in vertices_list])\n",
    "\n",
    "    prompt = (\n",
    "        \"You are given the OCR-extracted text from an image and the vertices list on the image of each line of text. \"\n",
    "        \"Your task is to arrange the provided OCR text into markdown format, preserving any tables or structure. \"\n",
    "        \"Only use the provided OCR text. \"\n",
    "        \"Join lines of text that are part of the same row and make sense of the text. \"\n",
    "        \"Add headers, line breaks, and other markdown formatting as needed. \"\n",
    "        \"If the OCR text is unclear, leave it as is. \"\n",
    "        \"Do not add, guess, or hallucinate any information. \"\n",
    "        \"Determine if a table is present in the text. \"\n",
    "        \"If a table is present, arrange the text into a markdown table, otherwise, return the text as is. \"\n",
    "        \"- If a table contains blank or empty cells, preserve them as blank in the markdown table (do not fill or merge them). \"\n",
    "        \"- Keep the table structure and number of columns/rows as in the original text, even if some cells are empty. \"\n",
    "        \"- The table columns are: ID, Name, Crew, Daily Output, Labor-Hours, Unit, Material, Labor, Equipment, Total, Total Incl O&P. \"\n",
    "        \"The vertices list is provided for reference, but do not use it to extract or transcribe any new information. \"\n",
    "        \"Use the vertices list only to understand the structure of the text. \"\n",
    "        \"Provide only the markdown output, without any extra commentary or code blocks.\\n\\n\"\n",
    "        \"OCR Text:\\n\"\n",
    "        f\"{ocr_text}\\n\\n\"\n",
    "        \"Vertices List:\\n\"\n",
    "        f\"{vertices_str}\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    markdown_text = response.choices[0].message.content.strip()\n",
    "    # Logging\n",
    "    if log_dir is not None:\n",
    "        log_file_path = os.path.join(log_dir, \"conversion_log.txt\")\n",
    "        with open(log_file_path, 'a', encoding='utf-8') as log_file:\n",
    "            log_file.write(f\"Timestamp: {datetime.datetime.now().isoformat()}\\n\")\n",
    "            log_file.write(\"OCR Text:\\n\")\n",
    "            log_file.write(ocr_text + \"\\n\")\n",
    "            log_file.write(\"Prompt:\\n\")\n",
    "            log_file.write(prompt + \"\\n\")\n",
    "            log_file.write(\"GPT Markdown Output:\\n\")\n",
    "            log_file.write(markdown_text + \"\\n\")\n",
    "            log_file.write(\"=\"*60 + \"\\n\\n\")\n",
    "    return markdown_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba0f2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vertices_list(vertices_list):\n",
    "    \"\"\"\n",
    "    Process the vertices list to extract the bounding boxes of each line of text.\n",
    "    \"\"\"\n",
    "    processed_vertices = []\n",
    "    for line in vertices_list:\n",
    "        processed_line = []\n",
    "        for vertex in line:\n",
    "            x = float(vertex.strip(\"()\").split(\",\")[0])\n",
    "            y = float(vertex.strip(\"()\").split(\",\")[1])\n",
    "            processed_line.append((x, y))\n",
    "        processed_vertices.append(processed_line)\n",
    "    return processed_vertices\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c7cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vertices_list(image_path, vertices_list):\n",
    "    \"\"\"\n",
    "    Plot the vertices list on the image.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    for line in vertices_list:\n",
    "        for vertex in line:\n",
    "            x = int(vertex[0])\n",
    "            y = int(vertex[1])\n",
    "            cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "    cv2.imshow(\"Vertices\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the image with vertices\n",
    "    output_path = os.path.splitext(image_path)[0] + \"_vertices.jpg\"\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Vertices image saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1cb398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, vertices_list):\n",
    "    \"\"\"\n",
    "    Preprocess the text to remove unwanted strings\n",
    "    and group lines of text.\n",
    "    \"\"\"\n",
    "    processed_lines = []\n",
    "\n",
    "    num_lines = len(text.split('\\n'))\n",
    "    num_vertices = len(vertices_list)\n",
    "\n",
    "    print(f\"Number of lines: {num_lines}\")\n",
    "    print(f\"Number of vertices: {num_vertices}\")\n",
    "\n",
    "    # return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f80d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patches in page_139.jpg: 3283\n",
      "Extracting text from page_139.jpg using OCR...\n",
      "Saved OCR text to C:/Users/scleb/Documents/bimsc25/GitHub/PDF-Markdown-AI/250510_test_images\\page_139_ocr.txt\n",
      "Saved vertices list to C:/Users/scleb/Documents/bimsc25/GitHub/PDF-Markdown-AI/250510_test_images\\page_139_vertices.txt\n",
      "type(ocr_text): <class 'str'>\n",
      "Number of lines: 1099\n",
      "Number of vertices: 3690\n",
      "Preprocessed OCR text: None\n",
      "All images converted to markdown successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a root window\n",
    "root = tk.Tk()\n",
    "try:\n",
    "    # Loop through each image file and convert it to markdown\n",
    "    # for image_file in image_files[:1]: # Limit to 1 file for testing\n",
    "    for image_file in image_files:\n",
    "        image_file_path = os.path.join(image_directory, image_file)\n",
    "\n",
    "        # Check if the markdown file already exists\n",
    "        markdown_file_name = os.path.splitext(image_file)[0] + \".md\"\n",
    "        markdown_file_path = os.path.join(markdown_directory, markdown_file_name)\n",
    "\n",
    "        if os.path.exists(markdown_file_path):\n",
    "            print(f\"Markdown file {markdown_file_name} already exists. Skipping conversion.\")\n",
    "            continue\n",
    "\n",
    "        # Calculate number of patches\n",
    "        num_patches = calculate_patches(image_file_path)\n",
    "        print(f\"Number of patches in {image_file}: {num_patches}\")\n",
    "\n",
    "        # Confirm with the user before proceeding\n",
    "        proceed = tk.messagebox.askyesno(\"Proceed?\", f\"Do you want to convert {image_file} to markdown?\\nNumber of patches: {num_patches}\")\n",
    "        if not proceed:\n",
    "            print(\"Conversion cancelled by user.\")\n",
    "            continue\n",
    "        \n",
    "        # Check if the file has already been processed with OCR\n",
    "        ocr_text_file_path = os.path.join(markdown_directory, f\"{os.path.splitext(image_file)[0]}_ocr.txt\")\n",
    "        processed_ocr_text_file_path = os.path.join(markdown_directory, f\"{os.path.splitext(image_file)[0]}_processed_ocr.txt\")\n",
    "\n",
    "        if os.path.exists(ocr_text_file_path):\n",
    "            print(f\"OCR text file {ocr_text_file_path} already exists. Skipping OCR.\")\n",
    "            with open(ocr_text_file_path, 'r') as ocr_file:\n",
    "                ocr_text = ocr_file.read()\n",
    "\n",
    "            # Check if the vertices file exists\n",
    "            vertices_file_path = os.path.join(markdown_directory, f\"{os.path.splitext(image_file)[0]}_vertices.txt\")\n",
    "            if os.path.exists(vertices_file_path):\n",
    "                print(f\"Vertices file {vertices_file_path} already exists. Skipping vertices extraction.\")\n",
    "                with open(vertices_file_path, 'r') as vertices_file:\n",
    "                    vertices_list = [line.strip() for line in vertices_file.readlines()]\n",
    "                \n",
    "                # Each line of the vertices list should be a list of four strings\n",
    "                vertices_list = [eval(vertices) for vertices in vertices_list]\n",
    "                print(f\"Loaded vertices list from {vertices_file_path}\")\n",
    "                # print(vertices_list[0])\n",
    "\n",
    "            else:\n",
    "                # Extract text using OCR\n",
    "                ocr_text, vertices_list = extract_text_with_google_vision(image_file_path)\n",
    "\n",
    "                # Save the vertices list to a file\n",
    "                with open(vertices_file_path, 'w', encoding='utf-8') as vertices_file:\n",
    "                    for vertices in vertices_list:\n",
    "                        vertices_file.write(f\"{vertices}\\n\")\n",
    "                print(f\"Saved vertices list to {vertices_file_path}\")\n",
    "\n",
    "        else:\n",
    "        # if True: # Forcing OCR processing for testing\n",
    "            # Extract text using OCR\n",
    "            print(f\"Extracting text from {image_file} using OCR...\")\n",
    "            ocr_text, vertices_list = extract_text_with_google_vision(image_file_path)\n",
    "\n",
    "            # Save the OCR text to a file\n",
    "            with open(ocr_text_file_path, 'w', encoding='utf-8') as ocr_file:\n",
    "                ocr_file.write(ocr_text)\n",
    "            print(f\"Saved OCR text to {ocr_text_file_path}\")\n",
    "\n",
    "            # Save the vertices list to a file\n",
    "            vertices_file_path = os.path.join(markdown_directory, f\"{os.path.splitext(image_file)[0]}_vertices.txt\")\n",
    "            with open(vertices_file_path, 'w', encoding='utf-8') as vertices_file:\n",
    "                for vertices in vertices_list:\n",
    "                    vertices_file.write(f\"{vertices}\\n\")\n",
    "            print(f\"Saved vertices list to {vertices_file_path}\")\n",
    "\n",
    "            # print(vertices_list[0])\n",
    "        \n",
    "        # # Process the vertices list to change the format to four tuples of floats\n",
    "        # vertices_list = process_vertices_list(vertices_list)\n",
    "        # print(f\"Processed vertices list: {vertices_list[0]}\")\n",
    "\n",
    "        # Plot the vertices list on the image\n",
    "        # plot_vertices_list(image_file_path, vertices_list)\n",
    "\n",
    "        print(f\"type(ocr_text): {type(ocr_text)}\")\n",
    "\n",
    "        # Preprocess the OCR text using the vertices list\n",
    "        ocr_text = preprocess_text(ocr_text, vertices_list)\n",
    "        print(f\"Preprocessed OCR text: {ocr_text}\")\n",
    "\n",
    "        # # Send the OCR text and the vertices to ChatGPT for markdown conversion\n",
    "        # markdown_text = convert_ocr_text_and_vertices_to_markdown(\n",
    "        #     ocr_text,\n",
    "        #     vertices_list,\n",
    "        #     client,\n",
    "        #     log_dir=markdown_directory\n",
    "        # )\n",
    "\n",
    "        # # Save the markdown text to a file\n",
    "        # with open(markdown_file_path, 'w', encoding='utf-8') as markdown_file:\n",
    "        #     markdown_file.write(markdown_text)\n",
    "\n",
    "        # # Print the markdown text\n",
    "        # print(f\"Markdown text for {image_file}:\\n{markdown_text}\")\n",
    "\n",
    "        # print(f\"OCR extracted text for {image_file}:\\n{ocr_text}\")\n",
    "\n",
    "    # Print a message indicating that the process is complete\n",
    "    print(\"All images converted to markdown successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Close the root window\n",
    "root.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
